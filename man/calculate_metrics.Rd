% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/validation.R
\name{calculate_metrics}
\alias{calculate_metrics}
\title{Calculate metric(s) for multiclass problem}
\usage{
calculate_metrics(true_y, predicted_y, average = "macro", metric = "F1")
}
\arguments{
\item{true_y}{factor containing true labels}

\item{predicted_y}{factor containing predicted labels}

\item{average}{specifies how to summarize overall F1.
* `macro` will take unweighted mean of F1 scores for each class,
* any other value will exclude overall summary from the returned data frame.}

\item{metric}{string or character vector with names of selected metrics
matching the names from caret::confusionMatrix output.}
}
\value{
Dataframe with metric results.
}
\description{
TODO: to be merged with `calculate_f1_metrics`, currently not done
since this requires complex regression tests and because this function
does not handle binary label problems.
}
\examples{
\dontrun{
phases <- c("euthymia", "depression", "mania")
yt <- factor(sample(x = phases, replace = TRUE, size = 100), levels = phases)
yp <- factor(sample(x = phases, replace = TRUE, size = 100), levels = phases)
calculate_metrics(yt, yp)
calculate_metrics(yt, yp, metric = c("Precision", "F1"))
}
}
